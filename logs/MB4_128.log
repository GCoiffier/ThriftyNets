Namespace(activ='tanh', auto_augment=False, batch_size=100, bias=False, checkpoint_freq=0, conv_mode='mb4', cutout=0, dataset='cifar10', epochs=200, gamma=0.5, history=5, iter=35, lr=0.1, min_lr=1e-05, model='resthrifty', momentum=0.9, name='MB4_128', nesterov=True, optimizer='sgd', patience=5, pool=[7], resume=None, seed=978518, size=128, test_batch_size=100, weight_decay=0.0005)Parameters : 15708
*******
Epoch : 1, train_loss : 1.5199400186538696, train_acc : 0.36658, lr : 0.1, test_loss : 1.565062387084961, test_acc : 0.4383, 
Epoch : 2, train_loss : 2.1438002586364746, train_acc : 0.3368, lr : 0.1, test_loss : 2.283498585510254, test_acc : 0.1764, 
Epoch : 3, train_loss : 1.9781666994094849, train_acc : 0.28456, lr : 0.1, test_loss : 1.8980846893310548, test_acc : 0.3044, 
Epoch : 4, train_loss : 2.061997413635254, train_acc : 0.2923, lr : 0.1, test_loss : 2.087039889526367, test_acc : 0.2555, 
Epoch : 5, train_loss : 1.8486453294754028, train_acc : 0.3093, lr : 0.1, test_loss : 1.9765972930908202, test_acc : 0.2792, 
Epoch : 6, train_loss : 1.8730674982070923, train_acc : 0.30528, lr : 0.1, test_loss : 1.8757872543334961, test_acc : 0.3169, 
Epoch : 7, train_loss : 1.9651280641555786, train_acc : 0.30982, lr : 0.1, test_loss : 1.992203074645996, test_acc : 0.2721, 
Epoch : 8, train_loss : 1.9890503883361816, train_acc : 0.31326, lr : 0.05, test_loss : 2.033807893371582, test_acc : 0.2531, 
Epoch : 9, train_loss : 1.6918160915374756, train_acc : 0.3289, lr : 0.05, test_loss : 1.782100975036621, test_acc : 0.352, 
Epoch : 10, train_loss : 1.665614128112793, train_acc : 0.34542, lr : 0.05, test_loss : 1.7642480010986328, test_acc : 0.3602, 
Epoch : 11, train_loss : 1.771052360534668, train_acc : 0.3589, lr : 0.05, test_loss : 1.8217153457641602, test_acc : 0.337, 
Epoch : 12, train_loss : 1.7958977222442627, train_acc : 0.36726, lr : 0.05, test_loss : 1.7793198303222657, test_acc : 0.3625, 
Epoch : 13, train_loss : 1.8211935758590698, train_acc : 0.3654, lr : 0.05, test_loss : 1.808157473754883, test_acc : 0.3552, 
Epoch : 14, train_loss : 1.6918007135391235, train_acc : 0.3814, lr : 0.025, test_loss : 1.7803589126586914, test_acc : 0.3544, 
Epoch : 15, train_loss : 1.597269892692566, train_acc : 0.39118, lr : 0.025, test_loss : 1.7044018005371093, test_acc : 0.3825, 
Epoch : 16, train_loss : 1.8565165996551514, train_acc : 0.39586, lr : 0.025, test_loss : 1.7346597793579102, test_acc : 0.372, 
Epoch : 17, train_loss : 1.6586614847183228, train_acc : 0.39468, lr : 0.025, test_loss : 1.7062075073242187, test_acc : 0.3824, 
Epoch : 18, train_loss : 1.5763676166534424, train_acc : 0.4053, lr : 0.025, test_loss : 1.5834577033996582, test_acc : 0.4291, 
Epoch : 19, train_loss : 1.5681660175323486, train_acc : 0.41968, lr : 0.025, test_loss : 1.641562013244629, test_acc : 0.4051, 
Epoch : 20, train_loss : 1.5656605958938599, train_acc : 0.4384, lr : 0.0125, test_loss : 1.5692908294677734, test_acc : 0.4227, 
Epoch : 21, train_loss : 1.4151095151901245, train_acc : 0.44542, lr : 0.0125, test_loss : 1.5094400260925294, test_acc : 0.4594, 
Epoch : 22, train_loss : 1.6022166013717651, train_acc : 0.45382, lr : 0.0125, test_loss : 1.5382068832397462, test_acc : 0.454, 
Epoch : 23, train_loss : 1.5332269668579102, train_acc : 0.45968, lr : 0.0125, test_loss : 1.5345016952514647, test_acc : 0.4458, 
Epoch : 24, train_loss : 1.4489777088165283, train_acc : 0.46384, lr : 0.0125, test_loss : 1.5346801933288574, test_acc : 0.4519, 
Epoch : 25, train_loss : 1.3939458131790161, train_acc : 0.46656, lr : 0.0125, test_loss : 1.4500989631652832, test_acc : 0.4782, 
Epoch : 26, train_loss : 1.4962180852890015, train_acc : 0.4681, lr : 0.0125, test_loss : 1.4048659774780274, test_acc : 0.4913, 
Epoch : 27, train_loss : 1.4947829246520996, train_acc : 0.47678, lr : 0.0125, test_loss : 1.4269626174926757, test_acc : 0.4933, 
Epoch : 28, train_loss : 1.2662878036499023, train_acc : 0.4869, lr : 0.0125, test_loss : 1.3871303504943848, test_acc : 0.4992, 
